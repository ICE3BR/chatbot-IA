### ğŸ“Œ **ICEBERG IA - Chatbot Inteligente com DeepSeek-R1**
**ICEBERG IA** Ã© um chatbot interativo baseado em **modelos de IA avanÃ§ados** e executado na **Ollama**, utilizando o modelo **DeepSeek-R1:8b** para processamento eficiente e inteligente de linguagem natural.

ğŸš€ **Destaques do projeto:**
- Modelo de IA **DeepSeek-R1:8b**, altamente otimizado para desempenho superior em **razonamento, cÃ³digo e matemÃ¡tica**.
- PersistÃªncia de **histÃ³rico de conversa** entre interaÃ§Ãµes.
- Suporte para **comandos interativos** no terminal.
- Interface otimizada para **uso eficiente de memÃ³ria e processamento**.

---

## ğŸ“¦ **InstalaÃ§Ã£o**
### 1ï¸âƒ£ **PrÃ©-requisitos**
Antes de iniciar, certifique-se de ter os seguintes requisitos instalados:

- **Python** (>= 3.8)
- **Ollama** ([instalar aqui](https://ollama.ai/))
- **DependÃªncias Python** (listadas abaixo)

### 2ï¸âƒ£ **Baixar e instalar dependÃªncias**
Clone o repositÃ³rio e instale as dependÃªncias:

```bash
git clone https://github.com/ICE3BR/chatbot-IA.git
cd chatbot-ia
uv sync
```

> âš ï¸ **Nota:** Se estiver utilizando **WSL2** ou **Ubuntu**, garanta que a **Ollama** esteja configurada corretamente.
> NecessÃ¡rio instalar o gerenciador de dependencias [UV](https://docs.astral.sh/uv/)

---

## ğŸš€ **Como executar**
ApÃ³s instalar tudo, execute o chatbot com:

```bash
python main.py
```

ğŸ”¹ O terminal exibirÃ¡ a mensagem de boas-vindas:  
```bash
Seja bem-vindo ao ICEBERG IA (Modelo: deepseek-r1:8b)
Digite 'sair' para encerrar o chatbot.
```

ğŸ”¹ Agora, vocÃª pode interagir digitando suas perguntas e recebendo respostas contextuais.

---

## ğŸ¤– **Modelos de IA disponÃ­veis**
O **ICEBERG IA** suporta mÃºltiplos modelos na **Ollama**. Atualmente, recomenda-se o **DeepSeek-R1:8b**, mas vocÃª pode alternar para outros modelos no cÃ³digo, alterando a variÃ¡vel `IA_MODEL`.

| Modelo             | ParÃ¢metros | Tamanho  | Comando Ollama                        |
|--------------------|-----------|----------|---------------------------------------|
| **DeepSeek-R1**    | 8B        | 4.9GB    | `ollama run deepseek-r1:8b`          |
| **DeepSeek-R1**    | 1.5B      | 2.7GB    | `ollama run deepseek-r1:1.5b`        |
| **Llama 3.1**      | 8B        | 5.2GB    | `ollama run llama3.1:8b`             |
| **Llama 3.2**      | 3B        | 3.5GB    | `ollama run llama3.2:3b`             |

> ğŸ’¡ **RecomendaÃ§Ã£o:** O **DeepSeek-R1:8B** Ã© um modelo **mais eficiente e rÃ¡pido**, consumindo **menos recursos** e entregando um desempenho comparÃ¡vel ao **GPT-O1**.

---

## ğŸ’¾ **HistÃ³rico de Conversa**
O chatbot mantÃ©m um **histÃ³rico de interaÃ§Ãµes** no arquivo `historico_conversa.txt`, permitindo a continuidade do diÃ¡logo entre sessÃµes.

ğŸ”¹ **Formato do histÃ³rico salvo:**
```
[28-01-2025 15:30:45] | VocÃª: OlÃ¡, como estÃ¡?
[28-01-2025 15:30:47] Bot: OlÃ¡! Estou bem. Como posso te ajudar?
```

> ğŸ” **ConfiguraÃ§Ã£o:** O histÃ³rico Ã© limitado a **200 interaÃ§Ãµes** por padrÃ£o (`MAX_INTERACOES = 200`), mas pode ser alterado no cÃ³digo.

---

## ğŸ› ï¸ **PersonalizaÃ§Ãµes**
VocÃª pode modificar o comportamento do chatbot alterando o arquivo `main.py`:

### ğŸ“Œ **Alterar modelo de IA**
Edite a variÃ¡vel `IA_MODEL` no cÃ³digo:

```python
IA_MODEL = "deepseek-r1:8b"  # Altere aqui para outro modelo
```

### ğŸ“Œ **Alterar limite de histÃ³rico**
Modifique a constante `MAX_INTERACOES` para ajustar o nÃºmero de mensagens armazenadas.

```python
MAX_INTERACOES = 100  # Define um novo limite
```

---

## ğŸ“œ **LicenÃ§a**
Este projeto Ã© distribuÃ­do sob a **MIT License**. O modelo **DeepSeek-R1** tambÃ©m Ã© licenciado sob **MIT**, permitindo uso comercial e modificaÃ§Ãµes.

ğŸ”— **Mais informaÃ§Ãµes sobre DeepSeek-R1:**  
[DeepSeek R1 no Ollama](https://ollama.ai/library/deepseek-r1)  
